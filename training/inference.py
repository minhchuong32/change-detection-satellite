"""
Inference & Post-processing - Ph·∫ßn c·ªßa CH∆Ø∆†NG
Nhi·ªám v·ª•: (7) Inference v√† h·∫≠u x·ª≠ l√Ω Change Mask
"""

import torch
import cv2
import numpy as np
from typing import Tuple, List


class ChangeDetectionInference:
    """Inference v√† h·∫≠u x·ª≠ l√Ω cho Change Detection"""
    
    def __init__(self, model, device='cuda', threshold=0.5):
        """
        Args:
            model: Trained U-Net model
            device: 'cuda' ho·∫∑c 'cpu'
            threshold: Ng∆∞·ª°ng ƒë·ªÉ t·∫°o binary mask
        """
        self.model = model
        self.device = device
        self.threshold = threshold
        self.model.to(device)
        self.model.eval()
    
    @torch.no_grad()
    def predict(self,
               img_before: np.ndarray,
               img_after: np.ndarray,
               apply_postprocess: bool = True) -> np.ndarray:
        """
        D·ª± ƒëo√°n change mask
        
        Args:
            img_before: ·∫¢nh tr∆∞·ªõc (H, W) ho·∫∑c (H, W, 1)
            img_after: ·∫¢nh sau (H, W) ho·∫∑c (H, W, 1)
            apply_postprocess: C√≥ √°p d·ª•ng post-processing kh√¥ng
        
        Returns:
            Binary change mask (H, W)
        """
        # Chu·∫©n b·ªã input
        input_tensor = self._prepare_input(img_before, img_after)
        input_tensor = input_tensor.to(self.device)
        
        # Forward pass
        output = self.model(input_tensor)
        
        # Convert to probability
        prob_mask = torch.sigmoid(output)
        
        # Threshold
        binary_mask = (prob_mask > self.threshold).float()
        
        # Convert to numpy
        binary_mask = binary_mask.cpu().numpy()[0, 0]
        
        # Post-processing
        if apply_postprocess:
            binary_mask = self.post_process(binary_mask)
        
        return binary_mask.astype(np.uint8)
    
    def _prepare_input(self,
                      img_before: np.ndarray,
                      img_after: np.ndarray) -> torch.Tensor:
        """
        Chu·∫©n b·ªã input cho model
        
        Returns:
            Tensor shape [1, 2, H, W]
        """
        # Ensure grayscale
        if len(img_before.shape) == 3:
            img_before = cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY)
        if len(img_after.shape) == 3:
            img_after = cv2.cvtColor(img_after, cv2.COLOR_BGR2GRAY)
        
        # Normalize to [0, 1]
        img_before = img_before.astype(np.float32) / 255.0
        img_after = img_after.astype(np.float32) / 255.0
        
        # Stack th√†nh [2, H, W]
        img_pair = np.stack([img_before, img_after], axis=0)
        
        # Add batch dimension [1, 2, H, W]
        img_tensor = torch.from_numpy(img_pair).unsqueeze(0)
        
        return img_tensor
    
    def post_process(self,
                    mask: np.ndarray,
                    min_area: int = 50,
                    kernel_size: int = 5) -> np.ndarray:
        """
        H·∫≠u x·ª≠ l√Ω change mask
        
        Pipeline:
        1. Morphological closing (l·∫•p l·ªó nh·ªè)
        2. Remove small objects (lo·∫°i nhi·ªÖu)
        3. Smooth edges
        
        Args:
            mask: Binary mask ƒë·∫ßu v√†o
            min_area: Di·ªán t√≠ch t·ªëi thi·ªÉu (pixels) ƒë·ªÉ gi·ªØ l·∫°i
            kernel_size: K√≠ch th∆∞·ªõc kernel cho morphology
        
        Returns:
            Cleaned binary mask
        """
        mask = mask.astype(np.uint8)
        
        # Step 1: Morphological closing
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        # Step 2: Remove small objects
        cleaned = self._remove_small_regions(closed, min_area)
        
        # Step 3: Smooth edges (optional)
        kernel_smooth = np.ones((3, 3), np.uint8)
        smoothed = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel_smooth)
        
        return smoothed
    
    def _remove_small_regions(self, mask: np.ndarray, min_area: int) -> np.ndarray:
        """Lo·∫°i b·ªè c√°c v√πng nh·ªè h∆°n min_area"""
        # Find connected components
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            mask, connectivity=8
        )
        
        # Create output mask
        output_mask = np.zeros_like(mask)
        
        # Keep only large components (skip label 0 = background)
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area >= min_area:
                output_mask[labels == i] = 1
        
        return output_mask
    
    def extract_change_contours(self, mask: np.ndarray) -> List[np.ndarray]:
        """
        Tr√≠ch xu·∫•t ƒë∆∞·ªùng vi·ªÅn c·ªßa c√°c v√πng thay ƒë·ªïi
        
        Returns:
            List of contours (m·ªói contour l√† array of points)
        """
        contours, _ = cv2.findContours(
            mask.astype(np.uint8),
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        return contours
    
    def visualize_changes(self,
                         img_after: np.ndarray,
                         mask: np.ndarray,
                         color: Tuple[int, int, int] = (255, 0, 0),
                         alpha: float = 0.5,
                         draw_contours: bool = True) -> np.ndarray:
        """
        T·∫°o visualization v·ªõi mask overlay
        
        Args:
            img_after: ·∫¢nh sau (ƒë·ªÉ v·∫Ω l√™n)
            mask: Change mask
            color: M√†u overlay (B, G, R)
            alpha: ƒê·ªô trong su·ªët
            draw_contours: C√≥ v·∫Ω ƒë∆∞·ªùng vi·ªÅn kh√¥ng
        
        Returns:
            RGB image v·ªõi visualization
        """
        # Convert to RGB n·∫øu c·∫ßn
        if len(img_after.shape) == 2:
            img_rgb = cv2.cvtColor(img_after, cv2.COLOR_GRAY2BGR)
        else:
            img_rgb = img_after.copy()
        
        # T·∫°o colored overlay
        overlay = img_rgb.copy()
        overlay[mask == 1] = color
        
        # Blend
        result = cv2.addWeighted(img_rgb, 1 - alpha, overlay, alpha, 0)
        
        # Draw contours
        if draw_contours:
            contours = self.extract_change_contours(mask)
            cv2.drawContours(result, contours, -1, (0, 255, 0), 2)
        
        return result


class BatchInference:
    """Inference cho nhi·ªÅu ·∫£nh"""
    
    def __init__(self, model, device='cuda', batch_size=4):
        self.inference = ChangeDetectionInference(model, device)
        self.batch_size = batch_size
    
    def predict_batch(self,
                     pairs: List[Tuple[str, str]],
                     output_dir: str = './predictions') -> List[np.ndarray]:
        """
        D·ª± ƒëo√°n cho nhi·ªÅu c·∫∑p ·∫£nh
        
        Args:
            pairs: List of (before_path, after_path)
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        
        Returns:
            List of predicted masks
        """
        import os
        from PIL import Image
        from tqdm import tqdm
        
        os.makedirs(output_dir, exist_ok=True)
        
        results = []
        
        for i, (before_path, after_path) in enumerate(tqdm(pairs, desc="Predicting")):
            # Load images
            img_before = np.array(Image.open(before_path).convert('L'))
            img_after = np.array(Image.open(after_path).convert('L'))
            
            # Predict
            mask = self.inference.predict(img_before, img_after)
            results.append(mask)
            
            # Save mask
            mask_filename = f"change_mask_{i:04d}.png"
            cv2.imwrite(os.path.join(output_dir, mask_filename), mask * 255)
            
            # Save visualization
            vis = self.inference.visualize_changes(img_after, mask)
            vis_filename = f"visualization_{i:04d}.png"
            cv2.imwrite(os.path.join(output_dir, vis_filename), vis)
        
        return results


# Test script
if __name__ == "__main__":
    from models.unet import UNet
    
    print("üß™ Testing Inference Pipeline...")
    
    # Load model (gi·∫£ s·ª≠ ƒë√£ train)
    model = UNet(n_channels=2, n_classes=1)
    # model.load_state_dict(torch.load('best_model.pth'))
    
    # T·∫°o inference engine
    inference = ChangeDetectionInference(model, device='cpu', threshold=0.5)
    
    # T·∫°o dummy data
    np.random.seed(42)
    img_before = np.random.randint(0, 255, (256, 256), dtype=np.uint8)
    img_after = np.random.randint(0, 255, (256, 256), dtype=np.uint8)
    
    # Predict
    mask = inference.predict(img_before, img_after, apply_postprocess=True)
    
    print(f"‚úÖ Predicted mask shape: {mask.shape}")
    print(f"‚úÖ Change pixels: {np.sum(mask == 1)}")
    
    # Visualize
    vis = inference.visualize_changes(img_after, mask)
    print(f"‚úÖ Visualization shape: {vis.shape}")
    
    print("\n‚úÖ Inference test completed!")