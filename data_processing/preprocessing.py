# """
# Image Registration & Alignment - Pháº§n cá»§a CHÆ¯Æ NG
# Nhiá»‡m vá»¥: (3) ÄÄƒng kÃ½ áº£nh, Resize/Padding
# """

# import cv2
# import numpy as np
# from typing import Tuple


# class ImageAligner:
#     """CÄƒn chá»‰nh vÃ  Ä‘Äƒng kÃ½ áº£nh Before-After"""
    
#     def __init__(self, feature_detector='orb'):
#         """
#         Args:
#             feature_detector: 'orb', 'sift', hoáº·c 'akaze'
#         """
#         self.detector_type = feature_detector
        
#         if feature_detector == 'orb':
#             self.detector = cv2.ORB_create(nfeatures=5000)
#         elif feature_detector == 'sift':
#             self.detector = cv2.SIFT_create()
#         elif feature_detector == 'akaze':
#             self.detector = cv2.AKAZE_create()
#         else:
#             raise ValueError(f"Unknown detector: {feature_detector}")
        
#         # Matcher
#         if feature_detector == 'sift':
#             self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)
#         else:
#             self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
    
#     def align_images(self, 
#                     img_before: np.ndarray, 
#                     img_after: np.ndarray,
#                     max_features: int = 500) -> Tuple[np.ndarray, np.ndarray]:
#         """
#         CÄƒn chá»‰nh img_after vá»›i img_before báº±ng feature matching
        
#         Pipeline:
#         1. Detect keypoints vÃ  descriptors
#         2. Match features
#         3. TÃ­nh homography matrix
#         4. Warp img_after
        
#         Args:
#             img_before: áº¢nh reference
#             img_after: áº¢nh cáº§n align
#             max_features: Sá»‘ features tá»‘i Ä‘a Ä‘á»ƒ match
        
#         Returns:
#             (img_before, aligned_img_after)
#         """
#         print("ğŸ”„ Aligning images...")
        
#         # Convert sang grayscale náº¿u cáº§n
#         if len(img_before.shape) == 3:
#             gray_before = cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY)
#         else:
#             gray_before = img_before
        
#         if len(img_after.shape) == 3:
#             gray_after = cv2.cvtColor(img_after, cv2.COLOR_BGR2GRAY)
#         else:
#             gray_after = img_after
        
#         # Step 1: Detect keypoints vÃ  descriptors
#         kp1, des1 = self.detector.detectAndCompute(gray_before, None)
#         kp2, des2 = self.detector.detectAndCompute(gray_after, None)
        
#         print(f"  Found {len(kp1)} keypoints in before image")
#         print(f"  Found {len(kp2)} keypoints in after image")
        
#         if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
#             print("  âš ï¸ Not enough keypoints for alignment, returning original")
#             return img_before, img_after
        
#         # Step 2: Match features
#         matches = self.matcher.knnMatch(des1, des2, k=2)
        
#         # Apply Lowe's ratio test
#         good_matches = []
#         for m_n in matches:
#             if len(m_n) == 2:
#                 m, n = m_n
#                 if m.distance < 0.75 * n.distance:
#                     good_matches.append(m)
        
#         print(f"  Found {len(good_matches)} good matches")
        
#         if len(good_matches) < 10:
#             print("  âš ï¸ Not enough good matches, returning original")
#             return img_before, img_after
        
#         # Step 3: TÃ­nh homography matrix
#         src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
#         dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        
#         H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)
        
#         if H is None:
#             print("  âš ï¸ Homography computation failed")
#             return img_before, img_after
        
#         # Step 4: Warp img_after
#         h, w = img_before.shape[:2]
#         aligned_after = cv2.warpPerspective(img_after, H, (w, h))
        
#         print("  âœ… Alignment completed")
#         return img_before, aligned_after
    
#     def check_alignment_quality(self,
#                                img1: np.ndarray,
#                                img2: np.ndarray) -> float:
#         """
#         ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng alignment báº±ng SSIM hoáº·c correlation
        
#         Returns:
#             Score tá»« 0-1 (1 = perfect alignment)
#         """
#         # Normalize
#         img1_norm = cv2.normalize(img1, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
#         img2_norm = cv2.normalize(img2, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        
#         # TÃ­nh correlation
#         correlation = np.corrcoef(img1_norm.flatten(), img2_norm.flatten())[0, 1]
        
#         return max(0, correlation)


# class ImageResizer:
#     """Resize vÃ  padding áº£nh vá» kÃ­ch thÆ°á»›c chuáº©n"""
    
#     @staticmethod
#     def resize_with_padding(img: np.ndarray,
#                            target_size: Tuple[int, int] = (256, 256),
#                            padding_value: int = 0) -> np.ndarray:
#         """
#         Resize áº£nh vÃ  thÃªm padding Ä‘á»ƒ giá»¯ tá»· lá»‡
        
#         Args:
#             img: áº¢nh input
#             target_size: (height, width) mong muá»‘n
#             padding_value: GiÃ¡ trá»‹ Ä‘á»ƒ padding (thÆ°á»ng lÃ  0)
        
#         Returns:
#             áº¢nh Ä‘Ã£ resize vÃ  padding
#         """
#         h, w = img.shape[:2]
#         target_h, target_w = target_size
        
#         # TÃ­nh tá»· lá»‡
#         scale = min(target_w / w, target_h / h)
        
#         # Resize giá»¯ tá»· lá»‡
#         new_w = int(w * scale)
#         new_h = int(h * scale)
#         resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
#         # Táº¡o canvas vá»›i padding
#         if len(img.shape) == 3:
#             canvas = np.full((target_h, target_w, img.shape[2]), padding_value, dtype=img.dtype)
#         else:
#             canvas = np.full((target_h, target_w), padding_value, dtype=img.dtype)
        
#         # Äáº·t áº£nh vÃ o giá»¯a canvas
#         y_offset = (target_h - new_h) // 2
#         x_offset = (target_w - new_w) // 2
#         canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
        
#         return canvas
    
#     @staticmethod
#     def center_crop(img: np.ndarray, crop_size: Tuple[int, int]) -> np.ndarray:
#         """Crop áº£nh tá»« giá»¯a"""
#         h, w = img.shape[:2]
#         crop_h, crop_w = crop_size
        
#         start_h = (h - crop_h) // 2
#         start_w = (w - crop_w) // 2
        
#         return img[start_h:start_h+crop_h, start_w:start_w+crop_w]


# # Test script
# if __name__ == "__main__":
#     print("ğŸ§ª Testing Image Aligner...")
    
#     # Táº¡o 2 áº£nh test vá»›i má»™t chÃºt dá»‹ch chuyá»ƒn
#     np.random.seed(42)
#     img1 = np.random.randint(0, 255, (300, 400), dtype=np.uint8)
    
#     # Táº¡o img2 báº±ng cÃ¡ch shift img1
#     M = np.float32([[1, 0, 10], [0, 1, 5]])  # Dá»‹ch 10px sang pháº£i, 5px xuá»‘ng
#     img2 = cv2.warpAffine(img1, M, (400, 300))
    
#     # Test alignment
#     aligner = ImageAligner(feature_detector='orb')
#     img1_aligned, img2_aligned = aligner.align_images(img1, img2)
    
#     # Check quality
#     quality = aligner.check_alignment_quality(img1_aligned, img2_aligned)
#     print(f"\nâœ… Alignment quality: {quality:.4f}")
    
#     # Test resizing
#     print("\nğŸ§ª Testing Image Resizer...")
#     resizer = ImageResizer()
#     resized = resizer.resize_with_padding(img1, target_size=(256, 256))
#     print(f"âœ… Resized shape: {resized.shape}")
    
#     print("\nâœ… All tests completed!")

# data_processing/preprocessing.py

import numpy as np
import cv2
from scipy.ndimage import uniform_filter # DÃ¹ng cho bá»™ lá»c cÆ¡ báº£n

# --- Pháº§n 1: Speckle Filtering (THÃ™Y) ---
# áº¢nh Ä‘áº§u vÃ o: áº¢nh numpy 
def apply_speckle_filter(image: np.ndarray, filter_type: str = 'Median'):
    """Ãp dá»¥ng cÃ¡c bá»™ lá»c giáº£m nhiá»…u Speckle/Noise (Lee, Frost, Median)."""
    
    if image.ndim > 2 and image.shape[2] == 3:
        # ÄÃ¢y lÃ  áº£nh RGB (LEVIR-CD), khÃ´ng pháº£i áº£nh SAR 1 kÃªnh Ä‘Æ¡n thuáº§n
        # Ãp dá»¥ng bá»™ lá»c cho tá»«ng kÃªnh hoáº·c chuyá»ƒn sang Grayscale trÆ°á»›c (tÃ¹y thuá»™c vÃ o yÃªu cáº§u)
        # Náº¿u lÃ  RGB, bá»™ lá»c median lÃ  lá»±a chá»n an toÃ n nháº¥t.
        if filter_type == 'Median':
            return cv2.medianBlur(image.astype(np.uint8), 3) # Kernel 3x3
        # Bá»™ lá»c Lee/Frost phá»©c táº¡p vÃ  thÆ°á»ng chá»‰ Ã¡p dá»¥ng cho áº£nh SAR 1 kÃªnh
        return image # Tráº£ vá» áº£nh gá»‘c náº¿u khÃ´ng cÃ³ bá»™ lá»c chuyÃªn dá»¥ng
    
    # Giáº£ láº­p Median cho áº£nh 1 kÃªnh:
    if filter_type == 'Median':
        return cv2.medianBlur(image.astype(np.uint8), 3)
    
    return image # Máº·c Ä‘á»‹nh tráº£ vá» áº£nh gá»‘c

# --- Pháº§n 2: Normalization (MINH) ---

def normalize_intensity(image: np.ndarray):
    """Chuáº©n hÃ³a cÆ°á»ng Ä‘á»™ áº£nh (Min-Max) sang dáº£i [0, 1]."""
    # Xá»­ lÃ½ normalization trÃªn tá»«ng kÃªnh (náº¿u lÃ  áº£nh RGB)
    if image.ndim > 2:
        normalized_img = np.zeros_like(image, dtype=np.float32)
        for i in range(image.shape[2]):
            channel = image[..., i]
            min_val = np.min(channel)
            max_val = np.max(channel)
            if max_val > min_val:
                normalized_img[..., i] = (channel - min_val) / (max_val - min_val)
            # Náº¿u min=max, kÃªnh Ä‘Ã³ sáº½ lÃ  0
        return normalized_img
    
    # Xá»­ lÃ½ grayscale
    min_val = np.min(image)
    max_val = np.max(image)
    if max_val == min_val:
         return np.zeros_like(image, dtype=np.float32)
         
    normalized_img = (image - min_val) / (max_val - min_val)
    return normalized_img.astype(np.float32)

# --- Pháº§n 3: Image Alignment (CHÆ¯Æ NG) ---

def align_images(before_img, after_img):
    """Image Registration (ÄÄƒng kÃ½ áº£nh) Ä‘á»ƒ cÄƒn chá»‰nh."""
    # Vá»›i dá»¯ liá»‡u patch 256x256 Ä‘Ã£ cáº¯t tá»« LEVIR-CD, bÆ°á»›c cÄƒn chá»‰nh thÆ°á»ng khÃ´ng cáº§n thiáº¿t
    # vÃ¬ áº£nh Ä‘Ã£ Ä‘Æ°á»£c cÄƒn chá»‰nh á»Ÿ má»©c Ä‘á»™ Scene.
    
    # Náº¿u cáº§n, báº¡n sáº½ sá»­ dá»¥ng ORB/SIFT Ä‘á»ƒ tÃ¬m homography vÃ  warp áº£nh.
    # Tuy nhiÃªn, Ä‘á»ƒ dá»± Ã¡n cháº¡y, ta bá» qua logic phá»©c táº¡p nÃ y.
    
    return before_img, after_img # Tráº£ vá» áº£nh gá»‘c