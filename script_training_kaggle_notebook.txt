"""
Script Training cho Kaggle Notebook
H∆∞·ªõng d·∫´n:
1. Upload dataset l√™n Kaggle Datasets
2. T·∫°o Notebook m·ªõi, b·∫≠t GPU T4 x2
3. Add dataset v√†o notebook
4. Clone GitHub repo
5. Ch·∫°y script n√†y
"""

# ==================== SETUP ====================

# Clone GitHub repository
print("üì• Cloning repository from GitHub...")
!git clone https://github.com/minhchuong32/change-detection-satellite.git
%cd change-detection-satellite

# Install dependencies
print("\nüì¶ Installing dependencies...")
!pip install -q albumentations==1.3.0 gradio==4.0.0

# Import libraries
import torch
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from IPython.display import clear_output

print("\n‚úÖ Setup completed!")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"Number of GPUs: {torch.cuda.device_count()}")


# ==================== LOAD DATA ====================

from data_processing.dataset_loader import SARDatasetLoader
from data_processing.pair_generator import BeforeAfterPairGenerator

print("\n" + "="*60)
print("LOADING DATA")
print("="*60)

# Path to Kaggle dataset
DATA_ROOT = "/kaggle/input/sar-change-detection-dataset/data"

# Load dataset
loader = SARDatasetLoader(data_root=DATA_ROOT)
dataset = loader.load_dataset()

# Generate pairs
pair_gen = BeforeAfterPairGenerator(dataset)
pairs = pair_gen.generate_pairs(before_season='spring', after_season='winter')

# Split dataset
splits = pair_gen.split_pairs(
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    random_seed=42
)

print(f"\n‚úÖ Data loaded successfully!")


# ==================== PREPROCESSING ====================

print("\n" + "="*60)
print("PREPROCESSING SAMPLE")
print("="*60)

from data_processing.preprocessing import SpeckleFilter, ImageNormalizer
from data_processing.ground_truth import GroundTruthGenerator
from PIL import Image

# Load m·ªôt c·∫∑p ·∫£nh m·∫´u ƒë·ªÉ test
sample_pair = splits['train'][0]
before_path, after_path, s_id, p_id = sample_pair

img_before = np.array(Image.open(before_path).convert('L'))
img_after = np.array(Image.open(after_path).convert('L'))

print(f"Sample: {s_id}/{p_id}")
print(f"Before shape: {img_before.shape}")
print(f"After shape: {img_after.shape}")

# Apply speckle filter
lee_before = SpeckleFilter.lee_filter(img_before, window_size=5)
lee_after = SpeckleFilter.lee_filter(img_after, window_size=5)

# Generate ground truth
gt_gen = GroundTruthGenerator(min_change_area=50)
mask = gt_gen.generate_change_mask(lee_before, lee_after, method='otsu')

# Visualize
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
axes[0].imshow(lee_before, cmap='gray')
axes[0].set_title('Before (Lee Filtered)')
axes[1].imshow(lee_after, cmap='gray')
axes[1].set_title('After (Lee Filtered)')
axes[2].imshow(mask, cmap='RdYlGn_r')
axes[2].set_title('Change Mask (Ground Truth)')
plt.tight_layout()
plt.show()

stats = gt_gen.compute_statistics(lee_before, lee_after, mask)
print("\nüìä Statistics:")
for key, value in stats.items():
    print(f"  {key}: {value}")


# ==================== CREATE MODEL ====================

print("\n" + "="*60)
print("CREATING MODEL")
print("="*60)

from models.unet import UNet, count_parameters

model = UNet(n_channels=2, n_classes=1, bilinear=True)
print(f"Model parameters: {count_parameters(model):,}")
print(f"Model size: {count_parameters(model) * 4 / 1024 / 1024:.2f} MB")


# ==================== TRAINING ====================

print("\n" + "="*60)
print("TRAINING")
print("="*60)

from torch.utils.data import DataLoader
from training.train import (
    ChangeDetectionDataset,
    get_train_transform,
    get_val_transform,
    train_model
)

# Create datasets
train_dataset = ChangeDetectionDataset(
    splits['train'],
    transform=get_train_transform(),
    use_cache=False  # Set True n·∫øu RAM ƒë·ªß l·ªõn
)

val_dataset = ChangeDetectionDataset(
    splits['val'],
    transform=get_val_transform(),
    use_cache=False
)

# Create dataloaders
train_loader = DataLoader(
    train_dataset,
    batch_size=8,  # Gi·∫£m n·∫øu b·ªã OOM
    shuffle=True,
    num_workers=2,
    pin_memory=True
)

val_loader = DataLoader(
    val_dataset,
    batch_size=8,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)

print(f"Train batches: {len(train_loader)}")
print(f"Val batches: {len(val_loader)}")

# Train model
history = train_model(
    model,
    train_loader,
    val_loader,
    num_epochs=50,  # TƒÉng l√™n n·∫øu mu·ªën train l√¢u h∆°n
    learning_rate=1e-4,
    device='cuda'
)


# ==================== PLOT TRAINING HISTORY ====================

print("\n" + "="*60)
print("TRAINING HISTORY")
print("="*60)

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Loss plot
axes[0].plot(history['train_loss'], label='Train Loss')
axes[0].plot(history['val_loss'], label='Val Loss')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Training & Validation Loss')
axes[0].legend()
axes[0].grid(True)

# IoU plot
axes[1].plot(history['train_iou'], label='Train IoU')
axes[1].plot(history['val_iou'], label='Val IoU')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('IoU')
axes[1].set_title('Training & Validation IoU')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()
plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
plt.show()


# ==================== TEST INFERENCE ====================

print("\n" + "="*60)
print("TESTING INFERENCE")
print("="*60)

from training.inference import ChangeDetectionInference

# Load best model
model.load_state_dict(torch.load('best_model.pth'))

# Create inference engine
inference = ChangeDetectionInference(model, device='cuda', threshold=0.5)

# Test tr√™n m·ªôt v√†i samples
test_samples = splits['test'][:5]

fig, axes = plt.subplots(len(test_samples), 3, figsize=(12, 4*len(test_samples)))

for idx, (before_path, after_path, s_id, p_id) in enumerate(test_samples):
    # Load images
    img_before = np.array(Image.open(before_path).convert('L'))
    img_after = np.array(Image.open(after_path).convert('L'))
    
    # Predict
    pred_mask = inference.predict(img_before, img_after, apply_postprocess=True)
    
    # Visualize
    vis = inference.visualize_changes(img_after, pred_mask)
    
    axes[idx, 0].imshow(img_before, cmap='gray')
    axes[idx, 0].set_title(f'{s_id}/{p_id} - Before')
    axes[idx, 0].axis('off')
    
    axes[idx, 1].imshow(img_after, cmap='gray')
    axes[idx, 1].set_title('After')
    axes[idx, 1].axis('off')
    
    axes[idx, 2].imshow(vis)
    axes[idx, 2].set_title(f'Change Detection (Area: {np.sum(pred_mask)*100/pred_mask.size:.2f}%)')
    axes[idx, 2].axis('off')

plt.tight_layout()
plt.savefig('test_results.png', dpi=150, bbox_inches='tight')
plt.show()


# ==================== SAVE MODEL ====================

print("\n" + "="*60)
print("SAVING MODEL")
print("="*60)

# Save model state dict
torch.save(model.state_dict(), 'best_model.pth')
print("‚úÖ Saved: best_model.pth")

# Save full model (optional)
torch.save(model, 'full_model.pth')
print("‚úÖ Saved: full_model.pth")

# Save to TorchScript (for deployment)
model.eval()
example_input = torch.randn(1, 2, 256, 256).cuda()
traced_model = torch.jit.trace(model, example_input)
traced_model.save('model_traced.pt')
print("‚úÖ Saved: model_traced.pt")


# ==================== DOWNLOAD MODEL ====================

print("\n" + "="*60)
print("DOWNLOADING MODEL")
print("="*60)

# T·∫£i file v·ªÅ m√°y local
from IPython.display import FileLink

print("üì• Click links below to download:")
display(FileLink('best_model.pth'))
display(FileLink('training_history.png'))
display(FileLink('test_results.png'))


# ==================== UPLOAD TO HUGGING FACE ====================

print("\n" + "="*60)
print("UPLOAD TO HUGGING FACE (Optional)")
print("="*60)

print("""
To upload model to Hugging Face:

1. Create account at https://huggingface.co
2. Create Model Repository: https://huggingface.co/new

3. Install huggingface_hub:
   !pip install huggingface_hub

4. Login:
   from huggingface_hub import HfApi, login
   login(token="your_token_here")

5. Upload:
   from huggingface_hub import upload_file
   upload_file(
       path_or_fileobj="best_model.pth",
       path_in_repo="best_model.pth",
       repo_id="your-username/your-model-name",
       repo_type="model"
   )
""")

print("\n" + "="*60)
print("üéâ TRAINING COMPLETED!")
print("="*60)
print("\nNext steps:")
print("1. Download best_model.pth")
print("2. Upload to Hugging Face Model Repository")
print("3. Deploy app on Hugging Face Spaces")